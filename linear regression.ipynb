{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_pySpark Basics: Linear Regression_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_By: Jeff Levy (jlevy@urban.org_\n",
    "\n",
    "_Last Updated: 24 June 2016, Spark v1.6.1_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Abstract: This guide will go over the basics of linear regression modeling using SGD in pySpark, and compare it to OLS._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do this in four steps:\n",
    "\n",
    "1. To begin with, we'll generate some sample data from a simple process so we know what the coefficients _should_ be\n",
    "2. Then we'll analyze it with traditional OLS using a pseudoinverse\n",
    "3. Then we'll analyze it with pySpark's method using stochastic gradient descent \n",
    "4. And finally we'll compare the known population paramaters and the two different forms of estimating them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to install a few Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-0.18.1.tar.gz\n",
      "Requirement already up-to-date: python-dateutil in ./venv/lib/python2.7/site-packages (from pandas)\n",
      "Requirement already up-to-date: pytz>=2011k in ./venv/lib/python2.7/site-packages (from pandas)\n",
      "Requirement already up-to-date: numpy>=1.7.0 in ./venv/lib64/python2.7/site-packages (from pandas)\n",
      "Requirement already up-to-date: six>=1.5 in ./venv/lib/python2.7/site-packages (from python-dateutil->pandas)\n",
      "Installing collected packages: pandas\n",
      "  Found existing installation: pandas 0.16.2\n",
      "    Uninstalling pandas-0.16.2:\n",
      "      Successfully uninstalled pandas-0.16.2\n",
      "  Running setup.py install for pandas: started\n",
      "    Running setup.py install for pandas: still running...\n",
      "    Running setup.py install for pandas: still running...\n",
      "    Running setup.py install for pandas: finished with status 'done'\n",
      "Successfully installed pandas-0.18.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "#pip.main(['install', 'pandas==0.16.2'])\n",
    "pip.main(['install', '--upgrade', 'pandas'])\n",
    "#pip.main(['install', 'statsmodels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0.18.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build a dataframe using Pandas.  This is the module used for non-distributed data analysis in Python - it cannot be used for the sort of big data Spark is designed for.  However, since we're dealing with toy data we can use it here just fine, and it will work in the memory of a single machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'y':[], 'x1':[], 'x2':[], 'x3':[]}\n",
    "a, b1, b2, b3 = 1, .2, .4, .5     #population paramters: intercept (a) and betas (b1, b2, b3)\n",
    "\n",
    "def make_row(data):\n",
    "    #generating some random x values for our data:\n",
    "    x1 = np.random.normal(10,2)\n",
    "    x2 = np.random.normal(17,3)\n",
    "    x3 = np.random.normal(8,1)\n",
    "    e = np.random.normal(0, .1) #a small error term\n",
    "    \n",
    "    #calculating our dependent variable from the data and the known population paramters\n",
    "    y = a + b1*x1 + b2*x2 + b3*x3 + e\n",
    "    \n",
    "    #adding the results for this observation to the data\n",
    "    data['x1'].append(x1)\n",
    "    data['x2'].append(x2)\n",
    "    data['x3'].append(x3)\n",
    "    data['y'].append(y)\n",
    "    return data\n",
    "    \n",
    "#creating 200 observations\n",
    "for _ in range(200):\n",
    "    data = make_row(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load it into a Pandas dataframe and look at the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.144736</td>\n",
       "      <td>18.529474</td>\n",
       "      <td>9.760265</td>\n",
       "      <td>15.299948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.301140</td>\n",
       "      <td>15.440311</td>\n",
       "      <td>8.625533</td>\n",
       "      <td>13.918040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.503888</td>\n",
       "      <td>18.697738</td>\n",
       "      <td>7.518186</td>\n",
       "      <td>13.925267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.164505</td>\n",
       "      <td>15.225154</td>\n",
       "      <td>9.609322</td>\n",
       "      <td>13.670369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.388564</td>\n",
       "      <td>16.854149</td>\n",
       "      <td>8.004604</td>\n",
       "      <td>13.821654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1         x2        x3          y\n",
       "0  10.144736  18.529474  9.760265  15.299948\n",
       "1  12.301140  15.440311  8.625533  13.918040\n",
       "2   8.503888  18.697738  7.518186  13.925267\n",
       "3  10.164505  15.225154  9.609322  13.670369\n",
       "4   9.388564  16.854149  8.004604  13.821654"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = pd.DataFrame(data)\n",
    "pdf[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use statsmodels, a Python module for statistical tools (again, not for distributed work), to do a normal OLS involving a pseudoinverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(pdf['y'], sm.add_constant(pdf[['x1', 'x2', 'x3']]))\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    1.018746\n",
       "x1       0.202988\n",
       "x2       0.399515\n",
       "x3       0.494584\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99513368576594396"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const     4.633138e-28\n",
       "x1       1.021059e-125\n",
       "x2       1.367133e-220\n",
       "x3       1.324201e-138\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we essentially get our original paramters back, have an R^2 of nearly one, and highly significant pvalues ust as we would expect (with some variation because we added an error term).  \n",
    "\n",
    "Now let's try the same thing using the tools avilable in pySpark that will work on very large distributed data.  It can build the RDD-based dataframe that we need straight from the Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdf = sqlContext.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+------------------+\n",
      "|                x1|                x2|                x3|                 y|\n",
      "+------------------+------------------+------------------+------------------+\n",
      "|10.144736104845618|18.529474419107736| 9.760264704880655|15.299947600283975|\n",
      "|  12.3011404989677| 15.44031056813525| 8.625532921681394| 13.91803995704791|\n",
      "| 8.503887608599818|18.697738478838776|7.5181857229865185|13.925266971339544|\n",
      "|10.164505228273514|15.225154016677319| 9.609321544034191|13.670368953178047|\n",
      "| 9.388563702719713|16.854148559954158| 8.004604345737487|13.821654454602573|\n",
      "|10.516058712914345|15.437628379951642|6.6957112434300345|12.530089286713215|\n",
      "|12.660066405263873|14.869981914637247| 7.783816162982566|13.290384811728076|\n",
      "| 9.930156485396305|15.785596093138121| 8.029172107453952|13.296763429620276|\n",
      "| 10.53923972522434| 19.92897605777253| 8.329562697075811|15.184952697233019|\n",
      "| 9.376886357328205| 16.90436494733737| 9.457475498602589|14.475164159139398|\n",
      "| 9.774663165039351|12.725721464833114| 8.440594138283105| 12.27843831372576|\n",
      "|10.873307367745982|20.485225164389306| 8.322427982625415|15.595139767157612|\n",
      "| 9.451028847459806|16.448768937413483| 7.313623007879667|13.030069388876806|\n",
      "| 11.29320755827188|15.871178918599089| 7.636477566493927| 13.29563158513926|\n",
      "|7.4955575357626625|17.844238142773975| 8.551691167815953|14.019981445077557|\n",
      "| 12.65540305773182| 18.05473868732969|  7.97533990316932| 14.65570012781397|\n",
      "| 9.700810993563056|15.949548675703957|7.3484135570341955|13.058743879777968|\n",
      "| 8.077824010372332|13.234887129151815| 7.406507176358105|11.458711922549698|\n",
      "|12.646843625501187|20.384586828655884| 7.439819150147124|15.426191900480001|\n",
      "|  7.24164800463525|18.777488814751234|7.9052236711067145| 14.02513040571313|\n",
      "+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
